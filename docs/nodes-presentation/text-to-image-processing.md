---
sidebar_position: 4
---

# Add image generation

The integration of AI-driven image generation transforms the visual aspect of your application. Leveraging the power of renowned models like FLUX from Black Forest Labs, DALL-E from OpenAI or Stable Diffusion from StabilityAI, you can generate unique visuals based on textual prompts or other parameters. Below, we introduce three primary image generation nodes and their requirements, but please note that **you can find many more models through the Replicate Node (Recraft SVG, Imagen, ...)**

## FLUX (With Replicate)

The FLUX family models are powerful text-to-image models, available through the Replicate node.

![OCR Workflow with Amazon Textract](/img/blog-images/flux-1-1.png)

## DALL-E (OpenAI)

The DALL-E node, a creation of OpenAI, leverages the renowned DALL-E model, which is designed to generate images from textual prompts. With this node, users can enter a text prompt, and DALL-E will generate a corresponding image, fusing the capabilities of language understanding and visual representation.

**DALL-E and Stable Diffusion nodes work the same, you can read the following part to learn more.**

## Stable Diffusion (StabilityAI)

The Stable Diffusion node is powered by StabilityAI. It offers a different approach to image generation, providing more controlled and stable image outputs based on the input prompts. Whether you're aiming for detailed illustrations, abstract visuals, or specific image types, the Stable Diffusion node can be a game-changer in your visual content generation process.

![Stable diffusion with inpout node](/img/blog-images/stable-diffusion-3-api-1.png)
